//! Workflow Executor Core
//!
//! This module implements the core functionality of the workflow executor.
//! It manages the execution of tasks in a directed acyclic graph (DAG) structure.
//!
//! # Execution Flow
//!
//! The workflow executor follows these steps:
//!
//! 1. Initialization Phase
//!    +-------------------+
//!    | Parse Workflow    |
//!    | Configuration     |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Build Task Graph  |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Initialize State  |
//!    +---------+---------+
//!              |
//!              v
//! 2. Execution Phase
//!    +-------------------+
//!    | Schedule Tasks    |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Monitor Progress  |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Handle Completion |
//!    +---------+---------+
//!              |
//!              v
//! 3. Completion Phase
//!    +-------------------+
//!    | Collect Results   |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Cleanup Resources |
//!    +---------+---------+
//!              |
//!              v
//!    +-------------------+
//!    | Generate Report   |
//!    +-------------------+
//!
//! # Key Components
//! - WorkflowExecutor: Main executor struct
//! - TaskDispatcher: Handles task scheduling and execution
//! - StateManager: Manages workflow state
//! - ErrorHandler: Processes errors and retries
//!
//! # Error Handling
//! The executor implements robust error handling with:
//! - Automatic retries for transient failures
//! - Circuit breakers for persistent failures
//! - Detailed error reporting
//!
//! # Performance Considerations
//! - Asynchronous task execution
//! - Parallel processing of independent tasks
//! - Efficient resource utilization
use std::{
    collections::{HashMap, HashSet, VecDeque},
    sync::Arc,
    time::Duration,
};

use chrono::Utc;
use log::{debug, error, info, warn};
use rust_i18n::t;
use serde_json::{json, Value};
use tokio::{
    sync::{Mutex, RwLock, Semaphore},
    task::JoinSet,
    time,
};

use crate::workflow::{
    config::{LoopConfig, NodeConfig, NodeType, ToolConfig, WorkflowLoop},
    context::{Context, NodeState},
    error::WorkflowError,
    executor::channel::{SharedChannel, WatchChannel},
    function_manager::FunctionManager,
    graph::WorkflowGraph,
    types::{WorkflowResult, WorkflowState},
};

/// å·¥ä½œæµæ‰§è¡Œå™¨ï¼Œè´Ÿè´£åŸºäº DAG çš„ä»»åŠ¡è°ƒåº¦å’Œæ‰§è¡Œ
#[derive(Clone)]
pub struct WorkflowExecutor {
    context: Arc<Context>,
    /// DAG å›¾æ„å»ºå™¨
    graph: Arc<WorkflowGraph>,
    /// å‡½æ•°ç®¡ç†å™¨
    function_manager: Arc<FunctionManager>,
    /// æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•°
    max_parallel: usize,
    /// å·¥ä½œæµçŠ¶æ€
    state: Arc<RwLock<WorkflowState>>,
    /// çŠ¶æ€é€šé“
    state_channel: WatchChannel<WorkflowState>,
    /// æš‚åœé€šé“
    pause_channel: SharedChannel<()>,
    /// æ¢å¤é€šé“
    resume_channel: SharedChannel<()>,
    /// å–æ¶ˆé€šé“
    cancel_channel: SharedChannel<()>,
    /// å¯è¿è¡Œçš„èŠ‚ç‚¹é˜Ÿåˆ—
    ready_queue: Arc<Mutex<VecDeque<NodeConfig>>>,
    /// è®°å½•å·²å®Œæˆçš„èŠ‚ç‚¹
    completed_nodes: Arc<Mutex<HashSet<String>>>,
}

impl WorkflowExecutor {
    /// Create a new workflow executor
    ///
    /// This method initializes a new workflow executor with the given context, function manager,
    /// maximum parallel tasks, and workflow graph. It also sets up the necessary channels for
    /// state management and control signals.
    ///
    /// # Arguments
    /// * `context` - The context of the workflow
    /// * `function_manager` - The function manager
    /// * `max_parallel` - The maximum number of parallel tasks
    /// * `graph` - The workflow graph
    ///
    /// # Returns
    /// * `WorkflowResult<Self>` - The created workflow executor
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The graph is invalid
    ///   - The context is not properly initialized
    pub fn create(
        context: Arc<Context>,
        function_manager: Arc<FunctionManager>,
        max_parallel: usize,
        graph: Arc<WorkflowGraph>,
    ) -> WorkflowResult<Self> {
        let state_channel = WatchChannel::new(WorkflowState::Init);
        let pause_channel = SharedChannel::new();
        let resume_channel = SharedChannel::new();
        let cancel_channel = SharedChannel::new();

        Ok(Self {
            context,
            graph,
            function_manager,
            state: Arc::new(RwLock::new(WorkflowState::Init)),
            state_channel,
            max_parallel,
            pause_channel,
            resume_channel,
            cancel_channel,
            ready_queue: Arc::new(Mutex::new(VecDeque::new())),
            completed_nodes: Arc::new(Mutex::new(HashSet::new())),
        })
    }

    /// Execute the workflow based on the DAG algorithm
    ///
    /// This method implements a parallel task scheduler using a directed acyclic graph (DAG).
    /// It performs the following steps:
    /// 1. Validates the execution state
    /// 2. Initializes the execution context
    /// 3. Processes tasks in topological order
    /// 4. Manages task dependencies and parallel execution
    /// 5. Ensures all tasks are completed
    ///
    /// # Algorithm Details
    /// - Uses topological sorting to determine task execution order
    /// - Limits parallel execution using a semaphore
    /// - Tracks task completion using a JoinSet
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if all tasks are executed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The workflow is in an invalid state
    ///   - Any task fails to execute
    ///   - Task dependencies cannot be resolved
    pub async fn execute(&mut self) -> WorkflowResult<()> {
        // çŠ¶æ€æ£€æŸ¥
        self.validate_execution_state().await?;

        let graph = self.graph.clone();
        info!(
            "Starting workflow execution with {} nodes",
            graph.node_count()
        );

        #[cfg(debug_assertions)]
        debug!(
            "Workflow nodes: {:?}",
            graph.nodes().map(|n| &n.id).collect::<Vec<_>>()
        );

        if graph.node_count() == 0 {
            info!("Workflow has no nodes");
            self.update_state(WorkflowState::Completed).await?;
            return Ok(());
        }

        // è½¬æ¢åˆ°è¿è¡ŒçŠ¶æ€
        self.update_state(WorkflowState::Running).await?;

        // å‡†å¤‡æ‰§è¡Œä¸Šä¸‹æ–‡
        let nodes = graph.nodes().cloned().collect::<Vec<_>>();

        // æ›´æ–° context ä¸­èŠ‚ç‚¹çŠ¶æ€ä¸º Pendingï¼ˆç­‰å¾…æ‰§è¡Œï¼‰
        for node in &nodes {
            self.context
                .update_node_state(&node.id, NodeState::Pending)
                .await;
        }

        // åˆå§‹åŒ–æ‰§è¡Œé˜Ÿåˆ—
        {
            let mut ready_queue = self.ready_queue.lock().await;
            *ready_queue = self.initialize_ready_queue(&nodes).await;
        }

        #[cfg(debug_assertions)]
        {
            let ready_queue = self.ready_queue.lock().await;
            debug!("Initial ready queue size: {}", ready_queue.len());
            if !ready_queue.is_empty() {
                debug!(
                    "Ready queue nodes: {:?}",
                    ready_queue.iter().map(|n| &n.id).collect::<Vec<_>>()
                );
            }
        }

        // å¹¶è¡Œæ§åˆ¶
        let semaphore = Arc::new(Semaphore::new(self.max_parallel));

        // ä»»åŠ¡é€šä¿¡é€šé“
        let mut task_set = JoinSet::new();

        // ä¸»æ‰§è¡Œå¾ªç¯
        while {
            let queue_empty = self.ready_queue.lock().await.is_empty();
            !queue_empty || task_set.len() > 0
        } {
            // å¤„ç†æ§åˆ¶ä¿¡å·
            self.process_control_signals().await?;

            // æ£€æŸ¥ä»»åŠ¡ç»“æœ
            let tasks_to_dispatch = {
                let mut queue = self.ready_queue.lock().await;
                queue.drain(..).collect::<Vec<_>>()
            };

            // æ´¾å‘æ–°ä»»åŠ¡
            self.dispatch_tasks(tasks_to_dispatch, &semaphore, &mut task_set)
                .await?;

            // ç­‰å¾…ä»»åŠ¡å®Œæˆ
            self.wait_for_task_completion(&mut task_set).await?;
        }

        // æœ€ç»ˆæ£€æŸ¥
        self.finalize_execution(&nodes).await
    }

    /// Validate the execution state
    ///
    /// This method checks if the workflow is in a valid state to start execution.
    /// It ensures that the workflow is not already running or in an invalid state.
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the state is valid,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The workflow is already running
    ///   - The workflow is in an invalid state
    async fn validate_execution_state(&self) -> WorkflowResult<()> {
        let state = self.state.read().await;
        if !matches!(*state, WorkflowState::Init | WorkflowState::Ready) {
            return Err(WorkflowError::InvalidState(format!(
                "{}",
                t!("workflow.executor.invalid_state")
            )));
        }
        Ok(())
    }

    async fn initialize_ready_queue(&self, nodes: &[NodeConfig]) -> VecDeque<NodeConfig> {
        let in_degree_map = self.graph.in_degree_map().lock().await.clone();

        #[cfg(debug_assertions)]
        debug!(
            "Initializing ready queue with in-degree map: {:?}",
            in_degree_map
        );

        let ready_nodes = nodes
            .iter()
            .filter(|n| in_degree_map.get(&n.id).copied().unwrap_or(1) == 0)
            .cloned()
            .collect::<Vec<_>>();

        #[cfg(debug_assertions)]
        debug!(
            "Initial ready nodes: {:?}",
            ready_nodes.iter().map(|n| &n.id).collect::<Vec<_>>()
        );

        VecDeque::from(ready_nodes)
    }

    /// Dispatch new tasks
    ///
    /// This method dispatches new tasks from the ready queue, respecting the maximum parallel
    /// task limit. It also sets up the necessary context for each task.
    ///
    /// # Arguments
    /// * `ready_queue` - The queue of ready tasks
    /// * `semaphore` - The semaphore for parallel control
    /// * `task_result_tx` - The sender channel for task results
    /// * `task_set` - The set of running tasks
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if all tasks are dispatched successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The ready queue is empty
    ///   - The semaphore cannot be acquired
    async fn dispatch_tasks(
        &self,
        tasks: Vec<NodeConfig>,
        semaphore: &Arc<Semaphore>,
        task_set: &mut JoinSet<WorkflowResult<()>>,
    ) -> WorkflowResult<()> {
        for node in tasks {
            let semaphore_clone = semaphore.clone();

            // å‡†å¤‡ä»»åŠ¡ä¸Šä¸‹æ–‡
            let node_id = node.id.clone();
            let self_ref = self.clone();

            // ç”Ÿæˆå¼‚æ­¥ä»»åŠ¡
            task_set.spawn(async move {
                let start_time = Utc::now();
                debug!("Starting node execution: {}", node_id);

                // æ‰§è¡ŒèŠ‚ç‚¹é€»è¾‘
                let result = match node.r#type {
                    NodeType::Group(_) => {
                        // ç«‹å³é‡Šæ”¾ä¿¡å·é‡ï¼Œä»…ç”¨äºè§¦å‘å­èŠ‚ç‚¹å…¥é˜Ÿ
                        let _ = semaphore_clone.acquire().await;
                        self_ref.execute_group_node(node).await
                    }
                    _ => {
                        // æŒæœ‰ä¿¡å·é‡ç›´åˆ°å¼‚æ­¥ä»»åŠ¡å®Œæˆï¼ˆé€šè¿‡å˜é‡ç»‘å®šï¼‰
                        let _hold_permit = semaphore_clone.acquire_owned().await;
                        self_ref.execute_task_node_with_retry(node).await
                    }
                };

                // å¤„ç†ä»»åŠ¡ç»“æœ
                self_ref
                    .handle_task_result(result, start_time, &node_id)
                    .await
            });
        }
        Ok(())
    }

    /// Handle task result
    ///
    /// This method processes the result of a completed task, updates the node state,
    /// and handles any errors that occurred during task execution.
    ///
    /// # Arguments
    /// * `result` - The result of the task
    /// * `start_time` - The start time of the task
    /// * `node_id` - The ID of the node
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the task result is processed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The task result is invalid
    ///   - The node state cannot be updated
    async fn handle_task_result(
        &self,
        result: WorkflowResult<()>,
        start_time: chrono::DateTime<Utc>,
        node_id: &str,
    ) -> WorkflowResult<()> {
        match result {
            Ok(()) => {
                // è®¡ç®—æ‰§è¡Œè€—æ—¶
                let duration = Utc::now() - start_time;
                info!(
                    "Node {} completed in {} ms",
                    node_id,
                    duration.num_milliseconds()
                );

                self.context
                    .update_node_state(&node_id, NodeState::Completed)
                    .await;

                // è·å–æ‰€æœ‰åç»§èŠ‚ç‚¹ï¼ˆæ˜¾å¼ + éšå¼ï¼‰
                let mut successors = self.graph.successors(node_id).to_vec();

                #[cfg(debug_assertions)]
                debug!("Direct successors of node {}: {:?}", node_id, successors);

                // ç¡®ä¿æ²¡æœ‰é‡å¤é¡¹
                successors.sort_unstable();
                successors.dedup();

                #[cfg(debug_assertions)]
                debug!("Final successors of node {}: {:?}", node_id, successors);
                // å‘é€ä»»åŠ¡ç»“æœ

                self.process_completed_tasks(node_id.to_string(), successors)
                    .await?;
                Ok(())

                // debug!("Sending task result for node {}", node_id);
                // task_result_sender
                //     .send(Ok((node_id.to_string(), successors)))
                //     .await
                //     .map_err(|e| WorkflowError::Execution(format!("Result channel closed: {}", e)))
            }
            Err(e) => {
                error!("Node {} failed: {}", node_id, e);

                self.context
                    .update_node_with_count(&node_id, NodeState::Failed(1))
                    .await;
                Err(e)
                // task_result_sender
                //     .send(Err(e))
                //     .await
                //     .map_err(|e| WorkflowError::Execution(format!("Error channel closed: {}", e)))
            }
        }
    }

    /// Process completed tasks
    ///
    /// This method handles the results of completed tasks, updates the task dependencies,
    /// and prepares the next set of tasks for execution.
    ///
    /// # Arguments
    /// * `task_result_rx` - The receiver channel for task results
    /// * `in_degree_map` - The map of node in-degrees
    /// * `ready_queue` - The queue of ready tasks
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if all completed tasks are processed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - Any task result is invalid
    ///   - Task dependencies cannot be updated
    async fn process_completed_tasks(
        &self,
        node_id: String,
        successors: Vec<String>,
    ) -> WorkflowResult<()> {
        debug!(
            "Processing completed task: {} with successors: {:?}",
            node_id, successors
        );

        #[cfg(debug_assertions)]
        debug!("Adding node {} to completed nodes", node_id);

        // æ·»åŠ èŠ‚ç‚¹åˆ°å·²å®ŒæˆèŠ‚ç‚¹é›†åˆ
        self.completed_nodes.lock().await.insert(node_id);

        for node_id in successors {
            #[cfg(debug_assertions)]
            debug!("Processing successor: {}", node_id);

            self.update_node_degree(&node_id).await?;
        }

        Ok(())
    }

    /// Update node in-degree
    ///
    /// This method updates the in-degree of a node in the workflow graph.
    ///
    /// # Arguments
    /// * `node_id` - The ID of the node
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the in-degree is updated successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The in-degree cannot be updated
    async fn update_node_degree(&self, node_id: &str) -> WorkflowResult<()> {
        let in_degree_map_ref = self.graph.in_degree_map();
        let mut in_degree_map = in_degree_map_ref.lock().await;

        if let Some(degree) = in_degree_map.get_mut(node_id) {
            let old_degree = *degree;
            *degree = degree.saturating_sub(1);

            #[cfg(debug_assertions)]
            debug!(
                "Updating node degree: {} from {} to {}",
                node_id, old_degree, *degree
            );

            let mut ready_queue = self.ready_queue.lock().await;
            if *degree == 0 {
                #[cfg(debug_assertions)]
                debug!("Node {} has zero in-degree, adding to ready queue", node_id);
                if let Some(node) = self.graph.get_node(node_id) {
                    ready_queue.push_back(node.clone());

                    #[cfg(debug_assertions)]
                    debug!(
                        "Added node {} to ready queue, queue size: {}",
                        node_id,
                        ready_queue.len()
                    );
                } else {
                    warn!("Node {} not found in graph nodes", node_id);
                }
            }
        } else {
            warn!("Node {} not found in in_degree_map", node_id);
        }
        Ok(())
    }

    /// Execute a task node with retry
    ///
    /// This method executes a task node with retry logic in case of failure.
    ///
    /// # Arguments
    /// * `node` - The configuration of the task node
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the task is executed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The task fails after all retries
    async fn execute_task_node_with_retry(&self, node: NodeConfig) -> WorkflowResult<()> {
        // é‡è¯•é€»è¾‘
        const MAX_RETRIES: usize = 3;
        const BASE_DELAY_MS: u64 = 100;

        let mut retries = 0;
        let mut current_delay = BASE_DELAY_MS;
        let function_manager = self.function_manager.clone();

        loop {
            match self
                .execute_task_node(node.clone(), function_manager.clone())
                .await
            {
                Ok(()) => return Ok(()),
                Err(e) if e.is_retriable() && retries < MAX_RETRIES => {
                    log::warn!(
                        "Retrying node {} (attempt {}/{}), error: {}",
                        node.id,
                        retries + 1,
                        MAX_RETRIES,
                        e
                    );
                    time::sleep(Duration::from_millis(current_delay)).await;
                    current_delay *= 2;
                    retries += 1;
                }
                Err(e) => return Err(e),
            }
        }
    }

    /// Execute a task node
    ///
    /// This method executes a task node and set the result to context output.
    ///
    /// # Arguments
    /// * `node` - The configuration of the task node
    /// * `function_manager` - The function manager
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the task is executed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The task fails to execute
    async fn execute_task_node(
        &self,
        node: NodeConfig,
        function_manager: Arc<FunctionManager>,
    ) -> WorkflowResult<()> {
        match node.r#type {
            NodeType::Task(ToolConfig {
                function,
                param,
                output,
            }) => {
                let function = function_manager
                    .get_function(&function)
                    .await
                    .map_err(|e| {
                        WorkflowError::FunctionNotFound(format!(
                            "Function {} not found: {}",
                            function, e
                        ))
                    })?;

                let params = self.context.resolve_params(param).await?;
                let result = function.execute(params, &self.context).await?;

                self.context
                    .set_output(output.unwrap_or(node.id), result)
                    .await?;
            }
            NodeType::Loop(_) => {
                return self.execute_loop_node(node, function_manager).await;
            }
            _ => {
                return Err(WorkflowError::Validation(format!(
                    "Invalid node type: {:?}",
                    node.r#type
                )));
            }
        }

        Ok(())
    }

    /// æ‰§è¡Œå¾ªç¯èŠ‚ç‚¹
    ///
    /// æ­¤æ–¹æ³•æ‰§è¡Œå¾ªç¯èŠ‚ç‚¹ï¼Œå¯¹è¾“å…¥æ•°æ®è¿›è¡Œè¿­ä»£å¤„ç†ï¼Œå¹¶å°†ç»“æœè®¾ç½®åˆ°ä¸Šä¸‹æ–‡è¾“å‡ºä¸­ã€‚
    ///
    /// # å‚æ•°
    /// * `node` - å¾ªç¯èŠ‚ç‚¹çš„é…ç½®
    /// * `function_manager` - å‡½æ•°ç®¡ç†å™¨
    ///
    /// # è¿”å›å€¼
    /// * `WorkflowResult<()>` - å¦‚æœå¾ªç¯èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› `Ok(())`ï¼Œå¦åˆ™è¿”å›åŒ…å«è¯¦ç»†ä¿¡æ¯çš„é”™è¯¯
    ///
    /// # é”™è¯¯
    /// * å¦‚æœä»¥ä¸‹æƒ…å†µå‘ç”Ÿï¼Œè¿”å› `WorkflowError`ï¼š
    ///   - è¾“å…¥æ•°æ®æ— æ•ˆ
    ///   - å‡½æ•°æ‰§è¡Œå¤±è´¥
    ///   - è¿‡æ»¤æ¡ä»¶æ— æ•ˆ
    async fn execute_loop_node(
        &self,
        node: NodeConfig,
        function_manager: Arc<FunctionManager>,
    ) -> WorkflowResult<()> {
        // ç›´æ¥ä»å‚æ•°ä¸­è§£æå‡º WorkflowLoop ç»“æ„
        match node.r#type {
            NodeType::Loop(LoopConfig {
                input,
                functions,
                limit,
                filter,
            }) => {
                // let params = node.params.clone().unwrap_or_default();
                // let loop_config: WorkflowLoop = serde_json::from_value(params)
                //     .map_err(|e| WorkflowError::Config(format!("æ— æ•ˆçš„å¾ªç¯èŠ‚ç‚¹é…ç½®: {}", e)))?;

                // è§£æè¾“å…¥å­—æ®µå¼•ç”¨
                let input_reference = input.trim();
                let input_data = self
                    .context
                    .resolve_params(Value::String(input_reference.to_string()))
                    .await?;

                // å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸ºå¯è¿­ä»£çš„é¡¹ç›®é›†åˆ
                let items: Vec<Value> = match input_data {
                    Value::Array(arr) => arr,
                    Value::Object(map) => {
                        // å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°†æ¯ä¸ªé”®å€¼å¯¹è½¬æ¢ä¸ºåŒ…å«é”®å’Œå€¼çš„å¯¹è±¡
                        map.into_iter()
                            .map(|(k, v)| {
                                json!({
                                    "key": k,
                                    "value": v
                                })
                            })
                            .collect()
                    }
                    _ => {
                        return Err(WorkflowError::Config(format!(
                            "å¾ªç¯èŠ‚ç‚¹è¾“å…¥å¿…é¡»æ˜¯æ•°ç»„æˆ–å¯¹è±¡ï¼Œä½†æ”¶åˆ°äº†: {}",
                            input_data.to_string()
                        )))
                    }
                };

                // åº”ç”¨é™åˆ¶
                let limit = limit.unwrap_or(items.len());
                let actual_limit = std::cmp::min(limit, items.len());

                // å‡†å¤‡ç»“æœæ•°ç»„
                let mut results = HashMap::with_capacity(actual_limit);

                // è¿­ä»£å¤„ç†æ¯ä¸ªé¡¹ç›®
                for item in items.into_iter().take(actual_limit) {
                    // è®¾ç½®å½“å‰é¡¹ç›®åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥ä¾¿è¿‡æ»¤æ¡ä»¶å’Œå‡½æ•°å¯ä»¥å¼•ç”¨å®ƒ
                    self.context
                        .set_output("item".to_string(), item.clone())
                        .await?;

                    // æ£€æŸ¥è¿‡æ»¤æ¡ä»¶
                    if let Some(filter) = &filter {
                        // ä½¿ç”¨ä¸“é—¨çš„æ¡ä»¶è§£ææ–¹æ³•å¤„ç†è¿‡æ»¤æ¡ä»¶
                        let pass = self.context.resolve_condition(filter).await?;
                        if !pass {
                            // å¦‚æœè¿‡æ»¤æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡æ­¤é¡¹ç›®
                            continue;
                        }
                    }

                    // æ‰§è¡Œæ‰€æœ‰å‡½æ•°
                    for tool_def in &functions {
                        // åˆ›å»ºå‡½æ•°è°ƒç”¨å‚æ•°
                        let function_name = &tool_def.function;
                        let function =
                            function_manager
                                .get_function(function_name)
                                .await
                                .map_err(|e| {
                                    WorkflowError::FunctionNotFound(format!(
                                        "å‡½æ•° {} æœªæ‰¾åˆ°: {}",
                                        function_name, e
                                    ))
                                })?;

                        // è§£æå‡½æ•°å‚æ•°
                        let mut function_params = tool_def.param.clone();
                        function_params = self.context.resolve_params(function_params).await?;

                        // æ‰§è¡Œå‡½æ•°
                        let result = function.execute(function_params, &self.context).await?;
                        // å°†å¤„ç†åçš„é¡¹ç›®æ·»åŠ åˆ°ç»“æœæ•°ç»„
                        results.insert(function_name, result);
                    }
                }

                // å°†ç»“æœè®¾ç½®åˆ°ä¸Šä¸‹æ–‡è¾“å‡ºä¸­
                for tool_def in &functions {
                    if results.contains_key(&tool_def.function) {
                        let result_value = results.get(&tool_def.function).unwrap();
                        self.context
                            .set_output(
                                tool_def.output.clone().unwrap_or(node.id.clone()),
                                result_value.clone(),
                            )
                            .await?;
                    }
                }
            }
            _ => {
                return Err(WorkflowError::Validation(format!(
                    "Invalid node type: {:?}",
                    node.r#type
                )));
            }
        }

        Ok(())
    }

    /// Execute a group node
    ///
    /// This method handles the completion of a group node in the workflow.
    /// Group nodes do not perform any tasks themselves; they are used to group
    /// related tasks and manage their dependencies. When all child nodes and
    /// dependencies of a group node are completed, this method is called to
    /// mark the group node as completed.
    ///
    /// # Arguments
    /// * node - The configuration of the group node
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the group node is marked as completed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The group node cannot be marked as completed
    async fn execute_group_node(&self, node: NodeConfig) -> WorkflowResult<()> {
        // ç»„èŠ‚ç‚¹è‡ªåŠ¨å®Œæˆï¼Œå®é™…ä¾èµ–ç”±è¾¹æ§åˆ¶
        debug!("Group node {} coordinator completed", node.id);

        Ok(())
    }

    /// Wait for task completion
    ///
    /// This method waits for the next task in the task set to complete and handles the result.
    ///
    /// # Arguments
    /// * `task_set` - The set of running tasks
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the task completes successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The task fails to execute
    ///   - The task set is empty
    async fn wait_for_task_completion(
        &self,
        task_set: &mut JoinSet<WorkflowResult<()>>,
    ) -> WorkflowResult<()> {
        match task_set.join_next().await {
            Some(Ok(Ok(_))) => Ok(()),
            Some(Ok(Err(e))) => Err(e),
            Some(Err(join_error)) => Err(WorkflowError::Execution(format!(
                "Task join error: {}",
                join_error
            ))),
            None => {
                time::sleep(Duration::from_millis(10)).await;
                Ok(())
            }
        }
    }

    /// Finalize the execution
    ///
    /// This method performs the final checks after all tasks have been executed, ensuring
    /// that all nodes have been processed and updating the workflow state accordingly.
    ///
    /// # Arguments
    /// * [nodes](cci:1://file:///Volumes/dev/personal/dev/ai/chatspeed/src-tauri/src/workflow/executor/core.rs:715:4-729:5) - The list of nodes in the workflow
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the execution is finalized successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - Not all nodes have been processed
    ///   - The workflow state cannot be update
    async fn finalize_execution(&self, nodes: &[NodeConfig]) -> WorkflowResult<()> {
        let completed = self.completed_nodes.lock().await;
        debug!("Finalizing execution. Completed nodes: {:?}", completed);
        debug!(
            "Total nodes: {}, Completed nodes: {}",
            nodes.len(),
            completed.len()
        );

        if completed.len() == nodes.len() {
            self.update_state(WorkflowState::Completed).await?;
            info!("Workflow execution completed");
            Ok(())
        } else {
            let missing = nodes
                .iter()
                .filter(|n| !completed.contains(&n.id))
                .map(|n| n.id.clone())
                .collect::<Vec<_>>();

            // æ£€æŸ¥æ¯ä¸ªç¼ºå¤±èŠ‚ç‚¹çš„ç±»å‹
            for node_id in &missing {
                if let Some(node_config) = self.graph.get_node(node_id) {
                    debug!(
                        "Missing node {} is of type {:?}",
                        node_id, node_config.r#type
                    );

                    // å¦‚æœæ˜¯ç»„èŠ‚ç‚¹ï¼Œæ£€æŸ¥å…¶å­èŠ‚ç‚¹çš„å®ŒæˆçŠ¶æ€
                    match node_config.r#type.clone() {
                        NodeType::Group(group_config) => {
                            let children = &group_config.nodes;
                            let children_status = children
                                .iter()
                                .map(|child| {
                                    if completed.contains(child) {
                                        format!("{}: completed", child)
                                    } else {
                                        format!("{}: not completed", child)
                                    }
                                })
                                .collect::<Vec<_>>();

                            debug!("Children of group node {}: {:?}", node_id, children_status);
                        }
                        _ => {}
                    }
                }
            }

            error!("Incomplete execution. Missing nodes: {:?}", missing);
            Err(WorkflowError::Execution(format!(
                "Missing nodes: {:?}",
                missing
            )))
        }
    }

    /// Process control signals
    ///
    /// This method processes control signals such as pause, resume, and cancel.
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the control signals are processed successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The control signals cannot be processed
    async fn process_control_signals(&mut self) -> WorkflowResult<()> {
        match *self.state.read().await {
            WorkflowState::Paused => {
                // ç­‰å¾…æ¢å¤æˆ–å–æ¶ˆä¿¡å·
                tokio::select! {
                    resume = self.resume_channel.recv() => {
                        if resume.is_some() {
                            // æ”¶åˆ°æ¢å¤ä¿¡å·ï¼Œç»§ç»­æ‰§è¡Œ
                            self.update_state(WorkflowState::Running).await?;
                            Ok(())
                        } else {
                            // ç»§ç»­ç­‰å¾…
                            time::sleep(time::Duration::from_millis(100)).await;
                            Ok(())
                        }
                    }
                    cancel = self.cancel_channel.recv() => {
                        if cancel.is_some() {
                            // æ”¶åˆ°å–æ¶ˆä¿¡å·ï¼Œåœæ­¢æ‰§è¡Œ
                            self.update_state(WorkflowState::Cancelled).await?;
                            Err(WorkflowError::Cancelled(
                                t!("workflow.executor.cancelled").to_string(),
                            ))
                        } else {
                            // ç»§ç»­ç­‰å¾…
                            time::sleep(time::Duration::from_millis(100)).await;
                            Ok(())
                        }
                    }
                    else => {
                        // ç»§ç»­ç­‰å¾…
                        time::sleep(time::Duration::from_millis(100)).await;
                        Ok(())
                    }
                }
            }
            WorkflowState::Running => {
                // æ£€æŸ¥æš‚åœæˆ–å–æ¶ˆä¿¡å·
                tokio::select! {
                    biased; // ä¼˜å…ˆå¤„ç†æ§åˆ¶ä¿¡å·

                    pause = self.pause_channel.recv() => {
                        if pause.is_some() {
                            self.update_state(WorkflowState::Paused).await?;
                            Ok(())
                        } else {
                            // ç»§ç»­ç­‰å¾…
                            Ok(())
                        }
                    }
                    cancel = self.cancel_channel.recv() => {
                        if cancel.is_some() {
                            self.update_state(WorkflowState::Cancelled).await?;
                            Err(WorkflowError::Cancelled(
                                t!("workflow.executor.cancelled").to_string(),
                            ))
                        } else {
                            // ç»§ç»­ç­‰å¾…
                            Ok(())
                        }
                    }
                    else => {
                        // æ²¡æœ‰æ§åˆ¶ä¿¡å·ï¼Œç»§ç»­æ‰§è¡Œ
                        Ok(())
                    }
                }
            }
            _ => Ok(()),
        }
    }

    /// Update workflow state
    ///
    /// This method updates the state of the workflow.
    ///
    /// # Arguments
    /// * `new_state` - The new state of the workflow
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the state is updated successfully,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The state cannot be updated
    async fn update_state(&self, new_state: WorkflowState) -> WorkflowResult<()> {
        let mut state = self.state.write().await;

        // éªŒè¯çŠ¶æ€è½¬æ¢æ˜¯å¦æœ‰æ•ˆ
        if !Self::valid_transition(&state, &new_state) {
            return Err(WorkflowError::InvalidState(format!(
                "{:?} -> {:?}",
                *state, new_state
            )));
        }

        // æ›´æ–°çŠ¶æ€
        *state = new_state.clone();

        // é€šçŸ¥çŠ¶æ€å˜åŒ–
        if let Err(_) = self.state_channel.tx.send(new_state) {
            return Err(WorkflowError::Execution(
                t!("workflow.executor.state_notification_error").to_string(),
            ));
        }

        Ok(())
    }

    /// Validate state transition
    ///
    /// This method validates if a state transition is valid.
    ///
    /// # Arguments
    /// * `current` - The current state of the workflow
    /// * `new` - The new state of the workflow
    ///
    /// # Returns
    /// * `bool` - Returns `true` if the transition is valid, otherwise `false`
    fn valid_transition(current: &WorkflowState, new: &WorkflowState) -> bool {
        match (current, new) {
            // åˆå§‹çŠ¶æ€å¯ä»¥è½¬æ¢ä¸ºå°±ç»ªæˆ–è¿è¡Œä¸­
            (WorkflowState::Init, WorkflowState::Ready) => true,
            (WorkflowState::Init, WorkflowState::Running) => true,

            // å°±ç»ªçŠ¶æ€å¯ä»¥è½¬æ¢ä¸ºè¿è¡Œä¸­æˆ–å–æ¶ˆ
            (WorkflowState::Ready, WorkflowState::Running) => true,
            (WorkflowState::Ready, WorkflowState::Cancelled) => true,

            // è¿è¡Œä¸­çŠ¶æ€å¯ä»¥è½¬æ¢ä¸ºæš‚åœã€å®Œæˆã€å¤±è´¥æˆ–å–æ¶ˆ
            (WorkflowState::Running, WorkflowState::Paused) => true,
            (WorkflowState::Running, WorkflowState::Completed) => true,
            (WorkflowState::Running, WorkflowState::Failed { .. }) => true,
            (WorkflowState::Running, WorkflowState::Error(_)) => true,
            (WorkflowState::Running, WorkflowState::FailedWithRetry { .. }) => true,
            (WorkflowState::Running, WorkflowState::ReviewFailed { .. }) => true,
            (WorkflowState::Running, WorkflowState::Cancelled) => true,

            // æš‚åœçŠ¶æ€å¯ä»¥è½¬æ¢ä¸ºè¿è¡Œä¸­æˆ–å–æ¶ˆ
            (WorkflowState::Paused, WorkflowState::Running) => true,
            (WorkflowState::Paused, WorkflowState::Cancelled) => true,
            (WorkflowState::Paused, WorkflowState::Failed { .. }) => true,

            // é”™è¯¯çŠ¶æ€å¯ä»¥é‡è¯•
            (WorkflowState::Error(_), WorkflowState::Running) => true,
            (WorkflowState::Error(_), WorkflowState::Failed { .. }) => true,

            // å¤±è´¥ä½†å¯é‡è¯•çŠ¶æ€å¯ä»¥è½¬ä¸ºè¿è¡Œä¸­æˆ–æ°¸ä¹…å¤±è´¥
            (WorkflowState::FailedWithRetry { .. }, WorkflowState::Running) => true,
            (WorkflowState::FailedWithRetry { .. }, WorkflowState::Failed { .. }) => true,

            // å®¡æ ¸å¤±è´¥çŠ¶æ€å¯ä»¥é‡è¯•
            (WorkflowState::ReviewFailed { .. }, WorkflowState::Running) => true,

            // å…¶ä»–è½¬æ¢ä¸å…è®¸
            _ => false,
        }
    }

    /// Pause workflow execution
    ///
    /// This method sends a signal to pause the workflow execution.
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the pause signal is sent,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The pause signal cannot be sent
    pub async fn pause(&mut self) -> WorkflowResult<()> {
        if let Err(_) = self.pause_channel.send(()).await {
            return Err(WorkflowError::Execution(
                t!("workflow.executor.pause_notification_error").to_string(),
            ));
        }
        Ok(())
    }

    /// Resume workflow execution
    ///
    /// This method sends a signal to resume the workflow execution.
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the resume signal is sent,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The resume signal cannot be sent
    pub async fn resume(&mut self) -> WorkflowResult<()> {
        if let Err(_) = self.resume_channel.send(()).await {
            return Err(WorkflowError::Execution(
                t!("workflow.executor.resume_notification_error").to_string(),
            ));
        }
        Ok(())
    }

    /// Cancel workflow execution
    ///
    /// This method sends a signal to cancel the workflow execution.
    ///
    /// # Returns
    /// * `WorkflowResult<()>` - Returns `Ok(())` if the cancel signal is sent,
    ///   otherwise returns an error with details
    ///
    /// # Errors
    /// * Returns `WorkflowError` if:
    ///   - The cancel signal cannot be sent
    pub async fn cancel(&mut self) -> WorkflowResult<()> {
        if let Err(_) = self.cancel_channel.send(()).await {
            return Err(WorkflowError::Execution(
                t!("workflow.executor.cancel_notification_error").to_string(),
            ));
        }
        Ok(())
    }

    /// Generate status map
    ///
    /// This method generates a map of status icons based on the current state of the workflow.
    ///
    /// # Returns
    /// * `HashMap<String, &'static str>` - Returns a map of status icons where the key is the node ID and the value is the status icon
    pub async fn generate_status_map(&self) -> HashMap<String, &'static str> {
        let mut status_map = HashMap::new();
        let mut tasks = Vec::new();

        // ä»ç¼“å­˜è·å–èŠ‚ç‚¹é…ç½®
        for node in self.graph.nodes() {
            let context = self.context.clone();
            let id = node.id.clone();
            let task = async move {
                let state = context.get_node_state(&id).await;
                let icon = match state {
                    NodeState::Completed => "âœ…",
                    NodeState::Failed { .. } => "âŒ",
                    NodeState::Retrying(_) => "ğŸ”„",
                    NodeState::Running => "â–¶ï¸",
                    NodeState::Paused => "â¸ï¸",
                    NodeState::Pending => "â³",
                };
                (id, icon)
            };
            tasks.push(task);
        }
        let results = futures::future::join_all(tasks).await;
        for (id, icon) in results {
            status_map.insert(id, icon);
        }

        status_map
    }

    /// Generate Markmap content
    ///
    /// This method generates a Markmap content based on the current state of the workflow.
    ///
    /// # Returns
    /// * `String` - Returns the Markmap content
    pub async fn generate_markmap(&self) -> String {
        let status_map = self.generate_status_map().await;
        let mut output = String::from("# Workflow Status\n\n");

        // æŒ‰ç…§åŸå§‹é¡ºåºéå†æ‰€æœ‰èŠ‚ç‚¹
        for node in self.graph.nodes() {
            match &node.r#type {
                NodeType::Group(group_config) => {
                    // å¤„ç†ç»„èŠ‚ç‚¹
                    let icon = status_map.get(&node.id).copied().unwrap_or("");
                    output.push_str(&format!("## {}{}\n", icon, node.id));

                    if let Some(desc) = &node.description {
                        output.push_str(&format!("- Description: {}\n", desc));
                    }

                    output.push_str(&format!("- Parallel: {}\n", group_config.parallel));

                    // æ·»åŠ å­èŠ‚ç‚¹
                    if !group_config.nodes.is_empty() {
                        output.push_str("- Child Nodes:\n");
                        for child_id in &group_config.nodes {
                            let child_icon = status_map.get(child_id).copied().unwrap_or("");
                            output.push_str(&format!("  - {}{}\n", child_icon, child_id));
                        }
                    }

                    output.push_str("\n");
                }
                NodeType::Task(_) => {
                    // å¤„ç†ä»»åŠ¡èŠ‚ç‚¹
                    let icon = status_map.get(&node.id).copied().unwrap_or("");
                    output.push_str(&format!("## {}{}\n", icon, node.id));

                    if let Some(desc) = &node.description {
                        output.push_str(&format!("- Description: {}\n", desc));
                    }

                    output.push_str("\n");
                }
                NodeType::Loop(_) => {
                    // å¤„ç†å¾ªç¯èŠ‚ç‚¹
                    let icon = status_map.get(&node.id).copied().unwrap_or("");
                    output.push_str(&format!("## {}{} (Loop)\n", icon, node.id));

                    if let Some(desc) = &node.description {
                        output.push_str(&format!("- Description: {}\n", desc));
                    }

                    output.push_str("\n");
                }
            }
        }

        output
    }
}
